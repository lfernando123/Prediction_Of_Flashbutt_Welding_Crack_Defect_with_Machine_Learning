{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " iDefect\n",
      "0    0.848887\n",
      "1    0.151113\n",
      "Name: proportion, dtype: float64\n",
      "Test class distribution:\n",
      " iDefect\n",
      "0    0.84897\n",
      "1    0.15103\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== RUNNING: LogisticRegression ===\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best params: {'clf__penalty': 'l1', 'clf__l1_ratio': None, 'clf__C': np.float64(0.0006951927961775605)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 22:41:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 22:41:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING: RandomForest ===\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best params: {'clf__n_estimators': 200, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 22:46:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 22:46:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING: XGBoost ===\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best params: {'clf__subsample': 0.6, 'clf__n_estimators': 400, 'clf__max_depth': 10, 'clf__learning_rate': 0.01, 'clf__colsample_bytree': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 22:48:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 22:48:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING: MLP ===\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best params: {'clf__learning_rate_init': 0.0001, 'clf__hidden_layer_sizes': (50,), 'clf__alpha': 0.0001, 'clf__activation': 'tanh'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 23:03:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 23:03:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Models comparison (sorted by F1) ===\n",
      "                model  accuracy  precision    recall        f1   roc_auc  \\\n",
      "0        RandomForest  0.889143   0.579000  0.974747  0.726474  0.942702   \n",
      "1             XGBoost  0.888889   0.579534  0.962963  0.723593  0.943879   \n",
      "2                 MLP  0.886092   0.575258  0.939394  0.713555  0.943198   \n",
      "3  LogisticRegression  0.872871   0.543278  0.993266  0.702381  0.920587   \n",
      "\n",
      "   best_threshold  \n",
      "0        0.425179  \n",
      "1        0.436902  \n",
      "2        0.604681  \n",
      "3        0.500000  \n",
      "\n",
      "Best model by F1: RandomForest\n",
      "Metrics: {'accuracy': 0.8891431477243834, 'precision': 0.579, 'recall': 0.9747474747474747, 'f1': 0.726474278544542, 'roc_auc': 0.9427017000392263, 'best_threshold': 0.4251785714285715}\n",
      "\n",
      "Explanation:\n",
      "- We optimized threshold to maximize F1 by default (balanced precision/recall) because in defect detection you often\n",
      "  want to balance false positives and false negatives. If the domain prefers catching every defect (minimize FN),\n",
      "  tune threshold to maximize recall; if false alarms are costly, tune for precision.\n",
      "- SMOTE was used to address class imbalance; class_weight used for models (where applicable) helps regularize minority preference.\n",
      "- Regularization (logistic penalty / alpha in MLP) reduces overfitting given many features.\n",
      "- The best F1 shows the best tradeoff for your use-case; the best precision/recall can be inspected in summary_df.\n",
      "\n",
      "\n",
      "All artifacts saved under ./artifacts/ (models, plots, CSVs). MLflow tracked runs under experiment: welding_defect_models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Full ML experiment script for flash butt welding defect prediction.\n",
    "- Four model families: LogisticRegression, RandomForest, XGBoost (or GradientBoosting fallback), MLPClassifier\n",
    "- Hyperparameter tuning via RandomizedSearchCV (StratifiedKFold)\n",
    "- SMOTE optional + class_weight adjustments\n",
    "- Multiple metrics: accuracy, precision, recall, f1, roc_auc (classification)\n",
    "- Regression metrics included in helper for completeness (RMSE, MAE, R2)\n",
    "- Error analysis: confusion matrices, misclassified class analysis, probability-based error inspection\n",
    "- Threshold tuning to maximize F1 / precision / recall as needed\n",
    "- Plots: confusion matrix, ROC curve, Precision-Recall curve, error distribution (probability hist)\n",
    "- MLflow tracking: params, metrics, model artifacts, plots\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix,\n",
    "                             classification_report)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Optional XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except Exception:\n",
    "    xgb_available = False\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "DATA_PATH = \"preprocessed_data.csv\"\n",
    "TARGET = \"iDefect\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "N_ITER_SEARCH = 30\n",
    "CV_SPLITS = 5\n",
    "MLFLOW_EXPERIMENT_NAME = \"welding_defect_models\"\n",
    "\n",
    "os.makedirs(\"artifacts/plots\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/models\", exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_proba=None, pos_label=1):\n",
    "    results = {}\n",
    "    results[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    results[\"precision\"] = precision_score(y_true, y_pred, zero_division=0, pos_label=pos_label)\n",
    "    results[\"recall\"] = recall_score(y_true, y_pred, zero_division=0, pos_label=pos_label)\n",
    "    results[\"f1\"] = f1_score(y_true, y_pred, zero_division=0, pos_label=pos_label)\n",
    "    if y_proba is not None and len(np.unique(y_true)) > 1:\n",
    "        try:\n",
    "            results[\"roc_auc\"] = roc_auc_score(y_true, y_proba)\n",
    "        except Exception:\n",
    "            results[\"roc_auc\"] = np.nan\n",
    "    else:\n",
    "        results[\"roc_auc\"] = np.nan\n",
    "    return results\n",
    "\n",
    "def plot_and_save_confusion_matrix(y_true, y_pred, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_and_save_roc(y_true, y_proba, title, fname):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(y_true, y_proba):.4f}\")\n",
    "    plt.plot([0,1],[0,1],\"k--\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_and_save_pr(y_true, y_proba, title, fname):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    # compute area under PR isn't built-in; just show curve\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(recall, precision)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_probability_hist(y_true, y_proba, title, fname):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(y_proba[y_true==0], label=\"class0\", stat=\"density\", kde=True)\n",
    "    sns.histplot(y_proba[y_true==1], label=\"class1\", stat=\"density\", kde=True)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted probability (positive)\")\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Custom MLP Classifier using PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define GPU-based MLP model\n",
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers=(100,), activation='relu'):\n",
    "        super(TorchMLP, self).__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            if activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            else:\n",
    "                layers.append(nn.Tanh())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Sklearn-compatible PyTorch wrapper\n",
    "class TorchMLPClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_layer_sizes=(100,), activation='relu', alpha=1e-4, learning_rate_init=1e-3,\n",
    "                 max_iter=200, batch_size=64, random_state=42):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = random_state\n",
    "        torch.manual_seed(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y = torch.tensor(y.values if isinstance(y, pd.Series) else y, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        dataset = TensorDataset(X, y)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model_ = TorchMLP(X.shape[1], self.hidden_layer_sizes, self.activation).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model_.parameters(), lr=self.learning_rate_init, weight_decay=self.alpha)\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            self.model_.train()\n",
    "            for Xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model_(Xb)\n",
    "                loss = criterion(output, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        self.model_.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model_(X).cpu().numpy()\n",
    "        return np.hstack((1 - preds, preds))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "# -------------------------\n",
    "# Load data\n",
    "# -------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "categorical_col = \"sSizeID\"\n",
    "\n",
    "# --- Define target and features ---\n",
    "# Replace 'Defect' with the actual column name of your target\n",
    "target_col = \"iDefect\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# --- One-hot encode sSizeID ---\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None, handle_unknown='ignore')\n",
    "encoded = encoder.fit_transform(X[[categorical_col]])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([categorical_col]))\n",
    "\n",
    "# --- Replace original sSizeID with encoded columns ---\n",
    "X = pd.concat([X.drop(columns=[categorical_col]).reset_index(drop=True),\n",
    "               encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# --- Split into train & test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test class distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "# -------------------------\n",
    "# CV\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# -------------------------\n",
    "# Preprocessing pipelines\n",
    "# -------------------------\n",
    "# We'll use median imputation + scaling. Use SMOTE in pipeline for training to handle imbalance.\n",
    "preproc_steps = [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Models and hyperparam grids\n",
    "# -------------------------\n",
    "models_to_run = {}\n",
    "\n",
    "# Logistic Regression (linear)\n",
    "lr_pipe = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', LogisticRegression(solver='saga', max_iter=5000, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "])\n",
    "lr_param_dist = {\n",
    "    'clf__C': np.logspace(-4, 4, 20),\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'clf__l1_ratio': [None, 0.1, 0.5, 0.9]\n",
    "}\n",
    "models_to_run['LogisticRegression'] = (lr_pipe, lr_param_dist)\n",
    "\n",
    "# Random Forest (tree-based)\n",
    "rf_pipe = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "])\n",
    "rf_param_dist = {\n",
    "    'clf__n_estimators': [100, 200, 400],\n",
    "    'clf__max_depth': [None, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__max_features': ['sqrt', 0.5]\n",
    "}\n",
    "models_to_run['RandomForest'] = (rf_pipe, rf_param_dist)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pipe = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE))\n",
    "])\n",
    "xgb_param_dist = {\n",
    "    'clf__n_estimators': [100, 200, 400],\n",
    "    'clf__max_depth': [3, 6, 10],\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'clf__subsample': [0.6, 0.8, 1.0],\n",
    "    'clf__colsample_bytree': [0.4, 0.6, 0.8]\n",
    "}\n",
    "models_to_run['XGBoost'] = (xgb_pipe, xgb_param_dist)\n",
    "\n",
    "# MLP (advanced)\n",
    "mlp_pipe = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('clf', TorchMLPClassifier(max_iter=200, random_state=RANDOM_STATE))\n",
    "])\n",
    "mlp_param_dist = {\n",
    "    'clf__hidden_layer_sizes': [(50,), (100,), (100,50)],\n",
    "    'clf__activation': ['relu', 'tanh'],\n",
    "    'clf__alpha': [1e-4, 1e-3],\n",
    "    'clf__learning_rate_init': [1e-3, 1e-4]\n",
    "}\n",
    "models_to_run['MLP'] = (mlp_pipe, mlp_param_dist)\n",
    "\n",
    "# -------------------------\n",
    "# MLflow setup\n",
    "# -------------------------\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# results store\n",
    "results_list = []  # will store dict with metrics, params, model_name\n",
    "\n",
    "# -------------------------\n",
    "# Helper: threshold tuning\n",
    "# -------------------------\n",
    "def tune_threshold(y_true, y_proba, metric='f1'):\n",
    "    \"\"\"\n",
    "    Returns best threshold in [0,1] maximizing metric (f1 / precision / recall).\n",
    "    y_proba is probability for positive class.\n",
    "    \"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    best_thresh = 0.5\n",
    "    best_score = -np.inf\n",
    "    # evaluate using thresholds from precision_recall_curve (note lengths differ)\n",
    "    for t in np.unique(np.concatenate(([0.5], thresholds))):\n",
    "        preds = (y_proba >= t).astype(int)\n",
    "        if metric == 'f1':\n",
    "            score = f1_score(y_true, preds, zero_division=0)\n",
    "        elif metric == 'precision':\n",
    "            score = precision_score(y_true, preds, zero_division=0)\n",
    "        elif metric == 'recall':\n",
    "            score = recall_score(y_true, preds, zero_division=0)\n",
    "        else:\n",
    "            score = f1_score(y_true, preds, zero_division=0)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresh = t\n",
    "    return best_thresh, best_score\n",
    "\n",
    "# -------------------------\n",
    "# Iterate models: tune, evaluate, log\n",
    "# -------------------------\n",
    "for model_name, (pipe, param_dist) in models_to_run.items():\n",
    "    print(f\"\\n=== RUNNING: {model_name} ===\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe, param_distributions=param_dist,\n",
    "        n_iter=min(N_ITER_SEARCH, max(1, len(param_dist) * 3)),\n",
    "        scoring='f1', cv=cv, n_jobs=-1, random_state=RANDOM_STATE, verbose=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best = search.best_estimator_\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "    # predict probabilities and classes on test set\n",
    "    try:\n",
    "        y_proba = best.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        # fallback to decision_function\n",
    "        try:\n",
    "            dfcn = best.decision_function(X_test)\n",
    "            y_proba = (dfcn - dfcn.min()) / (dfcn.max() - dfcn.min() + 1e-9)\n",
    "        except Exception:\n",
    "            y_proba = np.zeros(len(X_test))\n",
    "    y_pred_default = best.predict(X_test)\n",
    "\n",
    "    # threshold tuning for best F1\n",
    "    best_thresh, best_f1 = tune_threshold(y_test.values, y_proba, metric='f1')\n",
    "    y_pred_thresh = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "    # compute metrics for default (0.5) and tuned\n",
    "    metrics_default = classification_metrics(y_test, y_pred_default, y_proba)\n",
    "    metrics_tuned = classification_metrics(y_test, y_pred_thresh, y_proba)\n",
    "\n",
    "    # confusion matrix & plots\n",
    "    cm_fname = f\"artifacts/plots/{model_name}_confusion.png\"\n",
    "    plot_and_save_confusion_matrix(y_test, y_pred_thresh, f\"{model_name} Confusion (thresh={best_thresh:.3f})\", cm_fname)\n",
    "\n",
    "    roc_fname = f\"artifacts/plots/{model_name}_roc.png\"\n",
    "    if len(np.unique(y_test)) > 1:\n",
    "        plot_and_save_roc(y_test, y_proba, f\"{model_name} ROC\", roc_fname)\n",
    "\n",
    "        pr_fname = f\"artifacts/plots/{model_name}_pr.png\"\n",
    "        plot_and_save_pr(y_test, y_proba, f\"{model_name} Precision-Recall\", pr_fname)\n",
    "    else:\n",
    "        roc_fname = None\n",
    "        pr_fname = None\n",
    "\n",
    "    prob_hist_fname = f\"artifacts/plots/{model_name}_prob_hist.png\"\n",
    "    plot_probability_hist(y_test.values, y_proba, f\"{model_name} Pred Prob Dist\", prob_hist_fname)\n",
    "\n",
    "    # misclassification analysis\n",
    "    mis_idx = np.where(y_test.values != y_pred_thresh)[0]\n",
    "    # top misclassified with high-confidence (probability >=0.8 or <=0.2)\n",
    "    high_conf_mis = [(i, y_test.values[i], y_pred_thresh[i], y_proba[i]) for i in mis_idx if (y_proba[i] >= 0.8 or y_proba[i] <= 0.2)]\n",
    "    # store only a small sample\n",
    "    high_conf_mis_sample = high_conf_mis[:10]\n",
    "\n",
    "    # Save model artifact\n",
    "    model_fname = f\"artifacts/models/{model_name}_best.joblib\"\n",
    "    joblib.dump(best, model_fname)\n",
    "\n",
    "    # Log with MLflow\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_run\"):\n",
    "        # params\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        # log best params (flatten)\n",
    "        for k, v in search.best_params_.items():\n",
    "            mlflow.log_param(k, str(v))\n",
    "        # log metrics (tuned)\n",
    "        for metric_name, metric_val in metrics_tuned.items():\n",
    "            mlflow.log_metric(metric_name, float(metric_val))\n",
    "        # log default metrics too (prefix 'default_')\n",
    "        for k, v in metrics_default.items():\n",
    "            mlflow.log_metric(\"default_\" + k, float(v))\n",
    "        mlflow.log_metric(\"best_threshold\", float(best_thresh))\n",
    "        mlflow.log_metric(\"best_threshold_f1\", float(best_f1))\n",
    "\n",
    "        # log confusion matrix & plots as artifacts\n",
    "        mlflow.log_artifact(cm_fname, artifact_path=\"plots\")\n",
    "        if roc_fname:\n",
    "            mlflow.log_artifact(roc_fname, artifact_path=\"plots\")\n",
    "            mlflow.log_artifact(pr_fname, artifact_path=\"plots\")\n",
    "        mlflow.log_artifact(prob_hist_fname, artifact_path=\"plots\")\n",
    "\n",
    "        # log model\n",
    "        mlflow.sklearn.log_model(best, artifact_path=\"model\")\n",
    "\n",
    "        # Log a small CSV sample of high confidence misclassifications for inspection\n",
    "        if high_conf_mis_sample:\n",
    "            mis_df = pd.DataFrame(high_conf_mis_sample, columns=[\"idx_in_test\", \"true\", \"pred\", \"proba\"])\n",
    "            mis_csv = f\"artifacts/{model_name}_high_conf_mis.csv\"\n",
    "            mis_df.to_csv(mis_csv, index=False)\n",
    "            mlflow.log_artifact(mis_csv, artifact_path=\"analysis\")\n",
    "\n",
    "    # Append results summary\n",
    "    results_list.append({\n",
    "        \"model\": model_name,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"metrics_default\": metrics_default,\n",
    "        \"metrics_tuned\": metrics_tuned,\n",
    "        \"best_threshold\": best_thresh,\n",
    "        \"best_threshold_f1\": best_f1,\n",
    "        \"model_path\": model_fname,\n",
    "        \"cm_plot\": cm_fname,\n",
    "        \"roc_plot\": roc_fname,\n",
    "        \"prob_hist\": prob_hist_fname\n",
    "    })\n",
    "\n",
    "# -------------------------\n",
    "# Compare models: results table and plots\n",
    "# -------------------------\n",
    "summary_rows = []\n",
    "for r in results_list:\n",
    "    row = {\n",
    "        \"model\": r[\"model\"],\n",
    "        \"accuracy\": r[\"metrics_tuned\"][\"accuracy\"],\n",
    "        \"precision\": r[\"metrics_tuned\"][\"precision\"],\n",
    "        \"recall\": r[\"metrics_tuned\"][\"recall\"],\n",
    "        \"f1\": r[\"metrics_tuned\"][\"f1\"],\n",
    "        \"roc_auc\": r[\"metrics_tuned\"][\"roc_auc\"],\n",
    "        \"best_threshold\": r[\"best_threshold\"]\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=\"f1\", ascending=False).reset_index(drop=True)\n",
    "summary_df.to_csv(\"artifacts/models_summary.csv\", index=False)\n",
    "print(\"\\n=== Models comparison (sorted by F1) ===\")\n",
    "print(summary_df)\n",
    "\n",
    "# Plot comparison bar chart for key metrics\n",
    "plt.figure(figsize=(10,6))\n",
    "summary_df.set_index(\"model\")[[\"accuracy\",\"precision\",\"recall\",\"f1\"]].plot(kind=\"bar\")\n",
    "plt.title(\"Model comparison - key metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/plots/models_comparison_metrics.png\")\n",
    "plt.close()\n",
    "mlflow.log_artifact(\"artifacts/models_summary.csv\", artifact_path=\"comparison\")\n",
    "mlflow.log_artifact(\"artifacts/plots/models_comparison_metrics.png\", artifact_path=\"comparison\")\n",
    "\n",
    "# -------------------------\n",
    "# Final reporting: best metrics and explanation\n",
    "# -------------------------\n",
    "best_by_f1 = summary_df.iloc[0]\n",
    "print(\"\\nBest model by F1:\", best_by_f1[\"model\"])\n",
    "print(\"Metrics:\", best_by_f1[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\",\"best_threshold\"]].to_dict())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
